{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "from torchvision import models\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "from tqdm import tnrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/lijiayi/Documents/SMMA/data/pixel brightness.npy',\n",
       " '/Users/lijiayi/Documents/SMMA/data/pixel spectrum.npy']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = os.getcwd()\n",
    "np_files = glob.glob(os.path.join(path, \"data/*.npy\"))\n",
    "np_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df_lst = []\n",
    "for f in np_files:\n",
    "    df_lst.append(np.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "(512, 512, 1024)\n"
     ]
    }
   ],
   "source": [
    "brightness = df_lst[0]\n",
    "brightness.dtype = 'float64'\n",
    "print(df_lst[0].shape)\n",
    "\n",
    "spectrum = df_lst[1]\n",
    "spectrum.dtype = 'float64'\n",
    "print(df_lst[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 512, 1024])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spectrum_data = torch.tensor(spectrum)\n",
    "spectrum_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 512])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brightness_data = torch.tensor(brightness)\n",
    "brightness_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "xray_classification = np.load('xray classification.npy', allow_pickle=True)\n",
    "xray_classification = xray_classification.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_classification = np.load('pixel classification.npy', allow_pickle=True)\n",
    "pixel_classification = pixel_classification.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pixel_classification['domain 1'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(161, 512)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pixel_classification['domain 3'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# construct datasets of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dic = {}\n",
    "for key in ['domain 1', 'domain 2', 'domain 3']:\n",
    "    x, y = xray_classification[key].shape\n",
    "    dataset_dic[key] = []\n",
    "    for i in range(x):\n",
    "        for j in range(y):\n",
    "            temp_vec = np.append(xray_classification[key][i][j], pixel_classification[key][i][j])\n",
    "            dataset_dic[key].append(temp_vec) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_d1 = np.array(dataset_dic['domain 1'])\n",
    "y_d1 = np.ones(x_d1.shape[0])\n",
    "\n",
    "x_d2 = np.array(dataset_dic['domain 2'])\n",
    "y_d2 = np.ones(x_d2.shape[0]) * 2\n",
    "\n",
    "x_d3 = np.array(dataset_dic['domain 3'])\n",
    "y_d3 = np.ones(x_d3.shape[0]) * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109568, 1971)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_d2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = np.vstack((x_d1, x_d2, x_d3))\n",
    "data_y = np.hstack((y_d1, y_d2, y_d3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#permutate the datasets \n",
    "indx = np.random.permutation(len(data_y))\n",
    "data_x = data_x[indx]\n",
    "data_y = data_y[indx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_size = 10000\n",
    "testing_size = 1000\n",
    "\n",
    "training_x = data_x[0:training_size]\n",
    "training_y = data_y[0:training_size]\n",
    "\n",
    "testing_x = data_x[training_size:training_size + testing_size]\n",
    "testing_y = data_y[training_size:training_size + testing_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sample(n_way, n_support, n_query, datax, datay, test=False):\n",
    "    \"\"\"\n",
    "    Cite: https://github.com/cnielly/prototypical-networks-omniglot\n",
    "    \"\"\" \n",
    "    sample = []\n",
    "    K = np.random.choice(np.unique(datay), n_way, replace=False)\n",
    "    for cls in K:\n",
    "        datax_cls = datax[datay == cls]\n",
    "        perm = np.random.permutation(datax_cls)\n",
    "        sample_cls = perm[:(n_support+n_query)]\n",
    "        sample.append(sample_cls)\n",
    "    sample = np.array(sample).astype('float')\n",
    "    sample = torch.from_numpy(sample).float()\n",
    "    return ({\n",
    "      'data_vector': sample,\n",
    "      'n_way': n_way,\n",
    "      'n_support': n_support,\n",
    "      'n_query': n_query\n",
    "      })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define parameters for few-shot learning\n",
    "n_way = 3\n",
    "n_support = 10\n",
    "n_query = 20\n",
    "N = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 30, 1971])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = extract_sample(n_way, n_support, n_query, training_x, training_y)\n",
    "sample['data_vector'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constructing the embedding\n",
    "\n",
    "def load_protonet_conv(x_dim, hid_dim, z_dim):\n",
    "\n",
    "    \"\"\"\n",
    "    Cite: https://github.com/cnielly/prototypical-networks-omniglot\n",
    "    \n",
    "    Loads the prototypical network model\n",
    "    Arg:\n",
    "      x_dim (tuple): dimension of input data\n",
    "      hid_dim (int): dimension of hidden layers\n",
    "      z_dim (int): dimension of output\n",
    "    Returns:\n",
    "      Model (Class ProtoNet)\n",
    "      \"\"\"\n",
    "    encoder = nn.Sequential(\n",
    "                    nn.Linear(x_dim[-1], hid_dim),\n",
    "                    nn.Linear(hid_dim, hid_dim),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(hid_dim, hid_dim),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(hid_dim, z_dim))\n",
    "\n",
    "    return ProtoNet(encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_dist(x, y):\n",
    "    \"\"\"\n",
    "    Cite: https://github.com/cnielly/prototypical-networks-omniglot\n",
    "    Computes euclidean distance btw x and y\n",
    "    Args:\n",
    "      x (torch.Tensor): shape (n, d). n usually n_way*n_query\n",
    "      y (torch.Tensor): shape (m, d). m usually n_way\n",
    "    Returns:\n",
    "      torch.Tensor: shape(n, m). For each query, the distances to each centroid\n",
    "    \"\"\"\n",
    "    n = x.size(0)\n",
    "    m = y.size(0)\n",
    "    d = x.size(1)\n",
    "    assert d == y.size(1)\n",
    "\n",
    "    x = x.unsqueeze(1).expand(n, m, d)\n",
    "    y = y.unsqueeze(0).expand(n, m, d)\n",
    "\n",
    "    return torch.pow(x - y, 2).sum(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cite: https://github.com/cnielly/prototypical-networks-omniglot\n",
    "\n",
    "class ProtoNet(nn.Module):\n",
    "    def __init__(self, encoder):\n",
    "        super(ProtoNet, self).__init__()\n",
    "        self.encoder = encoder#.cuda()\n",
    "\n",
    "    def set_forward_loss(self, sample):\n",
    "        sample_vec = sample['data_vector']\n",
    "        n_way, n_support, n_query = sample['n_way'], sample['n_support'], sample['n_query']\n",
    "        x_support = sample_vec[:, :n_support]\n",
    "        x_query = sample_vec[:, n_support:]\n",
    "        \n",
    "        target_inds = torch.arange(0, n_way).view(n_way, 1, 1).expand(n_way, n_query, 1).long()\n",
    "        target_inds = torch.autograd.Variable(target_inds, requires_grad=False)\n",
    "        target_inds = target_inds#.cuda()\n",
    "        \n",
    "        x_s = x_support.contiguous().view(n_way * n_support, *x_support.size()[2:])\n",
    "        x_q = x_query.contiguous().view(n_way * n_query, *x_query.size()[2:])\n",
    "        \n",
    "        x = torch.cat([x_s,x_q], 0)\n",
    "        z = self.encoder(x.float())\n",
    "        z_dim = z.size(-1)\n",
    "        \n",
    "        z_proto = z[:n_way*n_support].view(n_way, n_support, z_dim).mean(1)\n",
    "        z_query = z[n_way*n_support:]\n",
    "        \n",
    "        #compute distances\n",
    "        dists = euclidean_dist(z_query, z_proto)\n",
    "\n",
    "        #compute probabilities\n",
    "        log_p_y = F.log_softmax(-dists, dim=1).view(n_way, n_query, -1)\n",
    "\n",
    "        loss_val = -log_p_y.gather(2, target_inds).squeeze().view(-1).mean()\n",
    "        _, y_hat = log_p_y.max(2)\n",
    "        acc_val = torch.eq(y_hat, target_inds.squeeze()).float().mean()\n",
    "        return loss_val, {\n",
    "            'loss': loss_val.item(),\n",
    "            'acc': acc_val.item(),\n",
    "            'y_hat': y_hat\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training \n",
    "def train(model, optimizer, n_way, n_support, n_query, max_epoch, epoch_size):\n",
    "    \"\"\"\n",
    "    Cite: https://github.com/cnielly/prototypical-networks-omniglot\n",
    "    Trains the protonet\n",
    "    Args:\n",
    "      model\n",
    "      optimizer\n",
    "      n_way (int): number of classes in a classification task\n",
    "      n_support (int): number of labeled examples per class in the support set\n",
    "      n_query (int): number of labeled examples per class in the query set\n",
    "      max_epoch (int): max epochs to train on\n",
    "      epoch_size (int): episodes per epoch\n",
    "    \"\"\"\n",
    "    #divide the learning rate by 2 at each epoch, as suggested in paper\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.5, last_epoch=-1)\n",
    "    epoch = 0 \n",
    "    stop = False #status to know when to stop\n",
    "    \n",
    "    print(\"---------START training-------------\")\n",
    "    \n",
    "    while epoch < max_epoch and not stop:\n",
    "        running_loss = 0.0\n",
    "        running_acc = 0.0\n",
    "        for episode in tnrange(epoch_size, desc=\"Epoch {:d} train\".format(epoch+1)):\n",
    "            if episode% 100 == 0:\n",
    "                print(\"=\", end='')\n",
    "            sample = extract_sample(n_way, n_support, n_query, training_x, training_y)\n",
    "            optimizer.zero_grad()\n",
    "            loss, output = model.set_forward_loss(sample)\n",
    "            running_loss += output['loss']\n",
    "            running_acc += output['acc']\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        epoch_loss = running_loss / epoch_size\n",
    "        epoch_acc = running_acc / epoch_size\n",
    "        print('Epoch {:d} -- Loss: {:.4f} Acc: {:.4f}'.format(epoch+1,epoch_loss, epoch_acc))\n",
    "        epoch += 1\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------START training-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-d96d59f33ff9>:25: TqdmDeprecationWarning: Please use `tqdm.notebook.trange` instead of `tqdm.tnrange`\n",
      "  for episode in tnrange(epoch_size, desc=\"Epoch {:d} train\".format(epoch+1)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d1dd019ebbe4b3e92fde807d84751f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 1 train', max=1000.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "Epoch 1 -- Loss: 0.2270 Acc: 0.9005\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93ece78604dc45c3a9d95a8bf33b2424",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 2 train', max=1000.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "Epoch 2 -- Loss: 0.1572 Acc: 0.9300\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "badc513354f94acbbaa0d5833cccee35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 3 train', max=1000.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "Epoch 3 -- Loss: 0.1428 Acc: 0.9357\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da4b9f078ab8498ca76d580aa7104817",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 4 train', max=1000.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "Epoch 4 -- Loss: 0.1341 Acc: 0.9386\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "093fc41c35c14870aef46a5bdcfe94b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 5 train', max=1000.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "Epoch 5 -- Loss: 0.1307 Acc: 0.9409\n"
     ]
    }
   ],
   "source": [
    "x_dim = sample['data_vector'].shape\n",
    "hid_dim = 60\n",
    "z_dim = 40\n",
    "\n",
    "model = load_protonet_conv(\n",
    "    x_dim,\n",
    "    hid_dim,\n",
    "    z_dim)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
    "max_epoch = 5\n",
    "epoch_size = 1000\n",
    "\n",
    "train(model, optimizer, n_way, n_support, n_query, max_epoch, epoch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-25-018ddb64b44b>:7: TqdmDeprecationWarning: Please use `tqdm.notebook.trange` instead of `tqdm.tnrange`\n",
      "  for episode in tnrange(test_episode):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc74121697b646b2b2d9faa0c05f7e93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test results -- Loss: 0.2893 Acc: 0.8847\n"
     ]
    }
   ],
   "source": [
    "def test(model, test_x, test_y, n_way, n_support, n_query, test_episode):\n",
    "    \"\"\"\n",
    "    Cite: https://github.com/cnielly/prototypical-networks-omniglot\n",
    "    \"\"\"\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    for episode in tnrange(test_episode):\n",
    "        sample = extract_sample(n_way, n_support, n_query, testing_x, testing_y)\n",
    "        loss, output = model.set_forward_loss(sample)\n",
    "        running_loss += output['loss']\n",
    "        running_acc += output['acc']\n",
    "    avg_loss = running_loss / test_episode\n",
    "    avg_acc = running_acc / test_episode\n",
    "    print('Test results -- Loss: {:.4f} Acc: {:.4f}'.format(avg_loss, avg_acc))\n",
    "\n",
    "n_way = 3\n",
    "n_support = 5\n",
    "n_query = 10\n",
    "\n",
    "test_x = testing_x\n",
    "test_y = testing_y\n",
    "\n",
    "test_episode = 2000\n",
    "\n",
    "test(model, test_x, test_y, n_way, n_support, n_query, test_episode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for region one 0.9470799999999998\n",
      "for region two 0.9465699999999997\n",
      "for region three 0.9274700000000001\n"
     ]
    }
   ],
   "source": [
    "N = 100\n",
    "acc_1 = 0\n",
    "acc_2 = 0\n",
    "acc_3 = 0\n",
    "for _ in range(N):\n",
    "    sample = extract_sample(n_way, n_support, 1000, training_x, training_y)\n",
    "    loss, output = model.set_forward_loss(sample)\n",
    "    output['y_hat'][0]\n",
    "    acc_1 += np.count_nonzero(output['y_hat'][0] == 0)/1000\n",
    "    acc_2 += np.count_nonzero(output['y_hat'][1] == 1)/1000\n",
    "    acc_3 += np.count_nonzero(output['y_hat'][2] == 2)/1000\n",
    "#region one classification accuracy\n",
    "print(\"for region one\", acc_1/N)\n",
    "print(\"for region two\", acc_2/N)\n",
    "print(\"for region three\", acc_3/N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': 0.11604665964841843,\n",
       " 'acc': 0.9449999928474426,\n",
       " 'y_hat': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 1, 1, 1],\n",
       "         [1, 2, 1,  ..., 2, 1, 2]])}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### output\n",
    "\n",
    "- n_way = 3, n_support = 5, n_query = 10: training accuracy = 0.9372; tesing accuracy = 0.9012;\n",
    "- n_way = 3, n_support = 5, n_query = 5: training accuracy = 0.9373; tesing accuracy = 0.9011;\n",
    "- n_way = 3, n_support = 5, n_query = 20: training accuracy = 0.949; tesing accuracy = 0.897;\n",
    "- n_way = 3, n_support = 20, n_query = 10: training accuracy = 0.9470; tesing accuracy = 0.8967;\n",
    "- n_way = 3, n_support = 10, n_query = 20: training accuracy = 0.9506; tesing accuracy = 0.8917;\n",
    "\n",
    "- n_way = 2, n_support = 5, n_query = 20: training accuracy = 0.9681; tesing accuracy = 0.9051;\n",
    "- n_way = 2, n_support = 5, n_query = 10: training accuracy = 0.9665; tesing accuracy = 0.9015;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProtoNet(\n",
       "  (encoder): Sequential(\n",
       "    (0): Linear(in_features=1971, out_features=60, bias=True)\n",
       "    (1): Linear(in_features=60, out_features=60, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=60, out_features=60, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Linear(in_features=60, out_features=40, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
